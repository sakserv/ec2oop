#!/bin/bash
###################################################
#
#  Name: init_mapred
#  Purpose: Initial mapreduce setup
#  Author: Shane Kumpf
#
###################################################

#
# Base variables
#
SCRIPT_NAME=`basename $0`
SCRIPT_DIR=`cd $(dirname $0) && pwd`

#
# Functions
#
function usage
{
    echo "Usage: $SCRIPT_NAME -h <hive server/metastore>"
    exit 1
}

#
# Validation
#
if [ `id -un` != "ec2-user" ]; then
    echo "ERROR: Must run as ec2-user"
    exit 1
fi

#
# Parse command line args
#
while getopts "h:" opt; do
    case $opt in
        h) 
            hive=$OPTARG;;
        \?) 
            echo "Invalid option: -$OPTARG"; usage;;
    esac
done

if [ -z "$hive" ]; then
    usage
fi

#
# Variables
#
work_dir="/tmp/work"
git_ec2oop_url="https://github.com/sakserv/ec2oop.git"
git_ec2_tools_url=" https://github.com/sakserv/ec2-tools"
helpers_dir="$work_dir/ec2oop/helpers"

#
# Prep work dir
#
if [ -d "$work_dir" ]; then
    echo -e "\n#####  Cleaning up previous work directory $work_dir"
    rm -rf $work_dir || exit 1
    echo "SUCCESS"
fi

# Create new work dir
if [ ! -d "$work_dir" ]; then
    echo -e "\n#####  Creating work directory $work_dir"
    mkdir -p $work_dir || exit 1
    echo "SUCCESS"
fi

# git clone ec2-tools into work dir
echo -e "\n#####  Cloning ec2-tools repo"
(cd $work_dir && git clone $git_ec2_tools_url) || exit 1
echo "SUCCESS"

# git clone ec2oop into work dir
echo -e "\n#####  Pulling repo $git_ec2oop_url to $work_dir"
(cd $work_dir && git clone $git_ec2oop_url) || exit 1
echo "SUCCESS"

#
# Source helpers
#
source $helpers_dir/scripts/usersAndGroups.sh
source $helpers_dir/scripts/directories.sh

#
# Main
#
echo -e "\nStarting $SCRIPT_NAME at `date`"

# Create the hive user and warehouse dirs
echo -e "\n#####  Creating the hive user and warehouse directories"
# Hive User
set -x
sudo -u hdfs hdfs dfs -mkdir -p /user/hive || exit 1
sudo -u hdfs hdfs dfs -chown $HIVE_USER:$HADOOP_GROUP /user/hive || exit 1
sudo -u hdfs hdfs dfs -ls /user | grep hive || exit 1
# Hive warehouse
sudo -u hdfs hdfs dfs -mkdir -p /apps/hive/warehouse || exit 1
sudo -u hdfs hdfs dfs -chown $HIVE_USER:$HADOOP_GROUP /apps || exit 1
sudo -u hdfs hdfs dfs -chmod 775 /apps || exit 1
sudo -u hdfs hdfs dfs -chown $HIVE_USER:$HADOOP_GROUP /apps/hive || exit 1
sudo -u hdfs hdfs dfs -chmod 775 /apps/hive || exit 1
sudo -u hdfs hdfs dfs -chown $HIVE_USER:$HADOOP_GROUP /apps/hive/warehouse || exit 1
sudo -u hdfs hdfs dfs -chmod 775 /apps/hive/warehouse || exit 1
sudo -u hdfs hdfs dfs -ls -R /apps || exit 1
# Hive scratch
sudo -u hdfs hdfs dfs -mkdir -p /tmp/scratch || exit 1
sudo -u hdfs hdfs dfs -chown $HIVE_USER:$HADOOP_GROUP /tmp/scratch || exit 1
sudo -u hdfs hdfs dfs -chmod 777 /tmp/scratch || exit 1
sudo -u hdfs hdfs dfs -ls /tmp | grep scratch || exit 1
set +x
echo "SUCCESS"



# start the metastore
echo -e "\n#####  Starting the metastore on $hive"
if ! ec2-ssh $hive "ps -ef | grep -v grep | grep -q HiveMetaStore"; then
    bash -x ec2-ssh $hive "sudo -u hive echo 'hive --service metastore 2>&1 | sudo -u hive tee '$HIVE_LOG_DIR'/hivemetastore.out' | at now" || exit 1
else
    echo -e "\n#####  Skipping start, metastore on $hive already running"
fi
echo "SUCCESS"

# start hiveserver 2
echo -e "\n#####  Starting hiveserver2 on $hive"
if ! ec2-ssh $hive "ps -ef | grep -v grep | grep -qi HiveServer2"; then
    bash -x ec2-ssh $hive "sudo -u hive echo '/usr/lib/hive/bin/hiveserver2 2>&1 | sudo -u hive tee '$HIVE_LOG_DIR'/hiveserver2.out' | at now" || exit 1
else
    echo -e "\n#####  Skipping start, hiveserver2 on $hive already running"
fi
echo "SUCCESS"


echo -e "\nFinished $SCRIPT_NAME at `date`"
exit 0
