#!/bin/bash
###################################################
#
#  Name: init_hdfs
#  Purpose: Initial namenode setup
#  Author: Shane Kumpf
#
###################################################

#
# Base variables
#
SCRIPT_NAME=`basename $0`
SCRIPT_DIR=`cd $(dirname $0) && pwd`

#
# Functions
#
function usage
{
    echo "Usage: $SCRIPT_NAME -n <namenode> -s <sec namenode> -d \"<datanode1 [datanode2...]>\""
    exit 1
}

#
# Validation
#
if [ `id -un` != "ec2-user" ]; then
    echo "ERROR: Must run as ec2-user"
    exit 1
fi

#
# Parse command line args
#
while getopts "n:s:d:" opt; do
    case $opt in
        n) 
            nn=$OPTARG;;
        s) 
            snn=$OPTARG;;
        d)
            dn_list="$OPTARG";;
        \?) 
            echo "Invalid option: -$OPTARG"; usage;;
    esac
done

if [ -z "$nn" ]; then
    usage
fi

if [ -z "$snn" ]; then
    usage
fi

if [ -z "$dn_list" ]; then
    usage
fi

#
# Variables
#
work_dir="/tmp/work"
git_ec2oop_url="https://github.com/sakserv/ec2oop.git"
git_ec2_tools_url=" https://github.com/sakserv/ec2-tools"
helpers_dir="$work_dir/ec2oop/helpers"

#
# Prep work dir
#
for node in $nn $snn $dn_list; do
    echo -e "\n#####  Setting up $work_dir on $node"
    if ec2-ssh $node "test -d $work_dir";  then
        echo -e "\n#####  Cleaning up previous work directory $work_dir"
        ec2-ssh $node "rm -rf $work_dir" || exit 1
        echo "SUCCESS"
    fi

    # Create new work dir
    if ! ec2-ssh $node "test -d $work_dir";  then
        echo -e "\n#####  Creating work directory $work_dir"
        ec2-ssh $node "mkdir -p $work_dir" || exit 1
        echo "SUCCESS"
    fi

    # git clone ec2-tools into work dir
    echo -e "\n#####  Cloning ec2-tools repo"
    ec2-ssh $node "(cd $work_dir && git clone $git_ec2_tools_url)" || exit 1
    echo "SUCCESS"

    # git clone ec2oop into work dir
    echo -e "\n#####  Pulling repo $git_ec2oop_url to $work_dir"
    ec2-ssh $node "(cd $work_dir && git clone $git_ec2oop_url)" || exit 1
    echo "SUCCESS"
done

#
# Source helpers
#
source $helpers_dir/scripts/usersAndGroups.sh
source $helpers_dir/scripts/directories.sh

#
# Main
#
echo -e "\nStarting $SCRIPT_NAME at `date`"

# format the namenode
is_formatted=""
for dir_name in $DFS_NAME_DIR; do 
    if ec2-ssh $nn "test -d $dir_name/current"; then
        is_formatted="true"
    fi
done
if [ -z "$is_formatted" ]; then 
    echo -e "\n#####  Formatting the namenode $nn"
    ec2-ssh $nn "sudo -u hdfs /usr/bin/hdfs namenode -format" || exit 1
else
    echo -e "Skipping format, namenode $nn already formatted"
fi
echo "SUCCESS"

# start the PNN
echo -e "\n#####  Starting the namenode $nn"
if ! ec2-ssh $nn "ps -ef | grep -v grep | grep -q proc_namenode"; then
    ec2-ssh $nn "sudo -u hdfs /usr/lib/hadoop/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR start namenode" || exit 1
else
    echo -e "Skipping start, namenode $nn already running"
fi
echo "SUCCESS"

# start the SNN
echo -e "\n#####  Starting the secondary namenode $snn"
if ! ec2-ssh $snn "ps -ef | grep -v grep | grep -q proc_secondarynamenode"; then
    ec2-ssh $snn "sudo -u hdfs /usr/lib/hadoop/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR start secondarynamenode" || exit 1
else
    echo -e "Skipping start, secondary namenode $snn already running"
fi
echo "SUCCESS"

# start the datanodes
for dn in $dn_list; do
    echo -e "\n#####  Starting the datanode $dn"
    if ! ec2-ssh $dn "ps -ef | grep -v grep | grep -q proc_datanode"; then
        ec2-ssh $dn "sudo -u hdfs /usr/lib/hadoop/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR start datanode" || exit 1
    else
        echo -e "Skipping start, datanode $dn already running"
    fi
    echo "SUCCESS"
done

# Create the hdfs /tmp dir and change perms
echo -e "\n#####  Creating the HDFS /tmp dir"
sudo -u hdfs hdfs dfs -mkdir -p /tmp || exit 1
sudo -u hdfs hdfs dfs -chmod 1777 /tmp || exit 1
echo "SUCCESS"

# Create the hdfs /user dir and change perms
echo -e "\n#####  Creating the HDFS /user dir"
sudo -u hdfs hdfs dfs -mkdir -p /user || exit 1
sudo -u hdfs hdfs dfs -chmod 775 /user || exit 1
echo "SUCCESS"

# Create the hdfs user directory for ec2-user
echo -e "\n#####  Creating the HDFS /user/ec2-user home dir"
sudo -u hdfs hdfs dfs -mkdir -p /user/ec2-user || exit 1
sudo -u hdfs hdfs dfs -chmod 775 /user/ec2-user || exit 1
sudo -u hdfs hdfs dfs -chown ec2-user:hadoop /user/ec2-user || exit 1
echo "SUCCESS"

# Show the contents of HDFS /
echo -e "\n#####  Listing HDFS / contents"
sudo -u hdfs hdfs dfs -ls / || exit 1
echo "SUCCESS"

echo -e "\nFinished $SCRIPT_NAME at `date`"
exit 0
